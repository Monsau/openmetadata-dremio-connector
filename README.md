
# ---
# English Translation

## Dremio to OpenMetadata | Automatic Ingestion Connector

### üì¶ Requirements

This project requires Python 3.8+ (tested up to 3.13). Using a virtual environment is strongly recommended:

```bash
python -m venv venv_dremio
venv_dremio\Scripts\activate  # Windows
source venv_dremio/bin/activate  # Linux/Mac
pip install -r requirements.txt
```

**Key dependencies:**

- `requests` (Dremio & OpenMetadata API)
- `python-dotenv` (environment variables)
- `pyarrow`, `pandas`, `polars` (data processing)
- `PyYAML` (YAML parsing)
- `psycopg2-binary`, `opensearch-py`, `elasticsearch` (DB connectors)
- `colorlog`, `structlog` (advanced logging)
- `pytest`, `pytest-cov` (testing, optional)
- See `requirements.txt` for the full list and exact versions.

**Notes:**
- Compatible with Python 3.8 to 3.13
- PyDremio (Arrow Flight API) requires Python 3.12+ and Dremio Arrow Flight enabled (port 32010)
- For full OpenMetadata ingestion, uncomment the `openmetadata-ingestion[...]` line in `requirements.txt` (optional, heavy)


...existing code...


# ---
# Traducci√≥n al Espa√±ol

## Dremio a OpenMetadata | Conector de Ingesta Autom√°tica

### üì¶ Requisitos

Este proyecto requiere Python 3.8+ (probado hasta 3.13). Se recomienda encarecidamente usar un entorno virtual:

```bash
python -m venv venv_dremio
venv_dremio\Scripts\activate  # Windows
source venv_dremio/bin/activate  # Linux/Mac
pip install -r requirements.txt
```

**Dependencias principales:**

- `requests` (API de Dremio y OpenMetadata)
- `python-dotenv` (variables de entorno)
- `pyarrow`, `pandas`, `polars` (procesamiento de datos)
- `PyYAML` (an√°lisis YAML)
- `psycopg2-binary`, `opensearch-py`, `elasticsearch` (conectores de BD)
- `colorlog`, `structlog` (logging avanzado)
- `pytest`, `pytest-cov` (pruebas, opcional)
- Consulte `requirements.txt` para la lista completa y versiones exactas.

**Notas:**
- Compatible con Python 3.8 a 3.13
- PyDremio (API Arrow Flight) requiere Python 3.12+ y Arrow Flight activado en Dremio (puerto 32010)
- Para la ingesta completa de OpenMetadata, descomente la l√≠nea `openmetadata-ingestion[...]` en `requirements.txt` (opcional, pesado)


...existing code...


# ---
# ÿßŸÑÿ™ÿ±ÿ¨ŸÖÿ© ÿ•ŸÑŸâ ÿßŸÑÿπÿ±ÿ®Ÿäÿ©

## ÿØÿ±ŸäŸÖŸà ÿ•ŸÑŸâ ÿ£Ÿàÿ®ŸÜ ŸÖŸäÿ™ÿßÿØÿßÿ™ÿß | ŸÖŸàÿµŸÑ ÿßŸÑÿßÿ≥ÿ™Ÿäÿπÿßÿ® ÿßŸÑÿ™ŸÑŸÇÿßÿ¶Ÿä

### üì¶ ÿßŸÑŸÖÿ™ÿ∑ŸÑÿ®ÿßÿ™

Ÿäÿ™ÿ∑ŸÑÿ® Ÿáÿ∞ÿß ÿßŸÑŸÖÿ¥ÿ±Ÿàÿπ Python 3.8 ÿ£Ÿà ÿ£ÿ≠ÿØÿ´ (ÿ™ŸÖ ÿßÿÆÿ™ÿ®ÿßÿ±Ÿá ÿ≠ÿ™Ÿâ 3.13). ŸäŸàÿµŸâ ÿ®ÿ¥ÿØÿ© ÿ®ÿßÿ≥ÿ™ÿÆÿØÿßŸÖ ÿ®Ÿäÿ¶ÿ© ÿßŸÅÿ™ÿ±ÿßÿ∂Ÿäÿ©:

```bash
python -m venv venv_dremio
venv_dremio\Scripts\activate  # Windows
source venv_dremio/bin/activate  # Linux/Mac
pip install -r requirements.txt
```

**ÿ£ŸáŸÖ ÿßŸÑÿßÿπÿ™ŸÖÿßÿØÿßÿ™:**

- `requests` (Ÿàÿßÿ¨Ÿáÿ© ÿ®ÿ±ŸÖÿ¨ÿ© ÿ™ÿ∑ÿ®ŸäŸÇÿßÿ™ Dremio ŸàOpenMetadata)
- `python-dotenv` (ŸÖÿ™ÿ∫Ÿäÿ±ÿßÿ™ ÿßŸÑÿ®Ÿäÿ¶ÿ©)
- `pyarrow`ÿå `pandas`ÿå `polars` (ŸÖÿπÿßŸÑÿ¨ÿ© ÿßŸÑÿ®ŸäÿßŸÜÿßÿ™)
- `PyYAML` (ÿ™ÿ≠ŸÑŸäŸÑ YAML)
- `psycopg2-binary`ÿå `opensearch-py`ÿå `elasticsearch` (ŸÖŸàÿµŸÑÿßÿ™ ŸÇŸàÿßÿπÿØ ÿßŸÑÿ®ŸäÿßŸÜÿßÿ™)
- `colorlog`ÿå `structlog` (ÿ™ÿ≥ÿ¨ŸäŸÑ ŸÖÿ™ŸÇÿØŸÖ)
- `pytest`ÿå `pytest-cov` (ÿßÿÆÿ™ÿ®ÿßÿ±ÿå ÿßÿÆÿ™Ÿäÿßÿ±Ÿä)
- ÿ±ÿßÿ¨ÿπ ŸÖŸÑŸÅ `requirements.txt` ŸÑŸÑÿ≠ÿµŸàŸÑ ÿπŸÑŸâ ÿßŸÑŸÇÿßÿ¶ŸÖÿ© ÿßŸÑŸÉÿßŸÖŸÑÿ© ŸàÿßŸÑÿ•ÿµÿØÿßÿ±ÿßÿ™ ÿßŸÑÿØŸÇŸäŸÇÿ©.

**ŸÖŸÑÿßÿ≠ÿ∏ÿßÿ™:**
- ŸÖÿ™ŸàÿßŸÅŸÇ ŸÖÿπ Python 3.8 ÿ•ŸÑŸâ 3.13
- Ÿäÿ™ÿ∑ŸÑÿ® PyDremio (Ÿàÿßÿ¨Ÿáÿ© Arrow Flight) Python 3.12+ Ÿàÿ™ŸÅÿπŸäŸÑ Arrow Flight ŸÅŸä Dremio (ÿßŸÑŸÖŸÜŸÅÿ∞ 32010)
- ŸÑÿßÿ≥ÿ™Ÿäÿπÿßÿ® OpenMetadata ÿßŸÑŸÉÿßŸÖŸÑÿå ŸÇŸÖ ÿ®ÿ•ŸÑÿ∫ÿßÿ° ÿßŸÑÿ™ÿπŸÑŸäŸÇ ÿπŸÑŸâ ÿ≥ÿ∑ÿ± `openmetadata-ingestion[...]` ŸÅŸä `requirements.txt` (ÿßÿÆÿ™Ÿäÿßÿ±Ÿäÿå ÿ´ŸÇŸäŸÑ)


...existing code...


# Dremio vers OpenMetadata | Connecteur d'Ingestion Automatique

## üì¶ Requirements

Le projet n√©cessite Python 3.8+ (test√© jusqu'√† 3.13). Il est fortement recommand√© d'utiliser un environnement virtuel¬†:

```bash
python -m venv venv_dremio
venv_dremio\Scripts\activate  # Windows
source venv_dremio/bin/activate  # Linux/Mac
pip install -r requirements.txt
```

**Principales d√©pendances¬†:**

- `requests` (API Dremio & OpenMetadata)
- `python-dotenv` (variables d'environnement)
- `pyarrow`, `pandas`, `polars` (traitement de donn√©es)
- `PyYAML` (parsing YAML)
- `psycopg2-binary`, `opensearch-py`, `elasticsearch` (connecteurs DB)
- `colorlog`, `structlog` (logging avanc√©)
- `pytest`, `pytest-cov` (tests, optionnel)
- Voir le fichier `requirements.txt` pour la liste compl√®te et les versions exactes.

**Notes¬†:**
- Compatible Python 3.8 √† 3.13
- PyDremio (API Arrow Flight) n√©cessite Python 3.12+ et Dremio Arrow Flight activ√© (port 32010)
- Pour l'ingestion OpenMetadata compl√®te, d√©commentez la ligne `openmetadata-ingestion[...]` dans `requirements.txt` (optionnel, lourd)


Ce connecteur permet l'int√©gration automatis√©e des sources Dremio et des Virtual Data Sets (VDS) dans OpenMetadata, en exposant chaque source comme un service CustomDB. Il s'adresse aux √©quipes souhaitant industrialiser la gestion de leurs m√©tadonn√©es Dremio dans OpenMetadata.


## Fonctionnalit√©s principales

```mermaid
flowchart LR
    D[üóÑÔ∏è Dremio] --> |Scan automatique| C[üîÑ Connecteur]
    C --> |Cr√©ation service| OM[üìä OpenMetadata]
    
    subgraph D_Sources[Dremio Sources]
        D1[MinIO S3]
        D2[PostgreSQL]
        D3[MySQL]
        D4[Autres...]
    end
    
    subgraph VDS[Virtual Data Sets]
        V1[Analytics VDS]
        V2[Reporting VDS]
        V3[Clean VDS]
    end
    
    subgraph OM_Result[OpenMetadata Result]
        S1[üì¶ Service: Dremio Data Lake]
        S2[üìã Sch√©mas par source]
        S3[üîç Tables & Vues]
        S4[‚ö° Pipeline auto]
    end
    
    D_Sources --> C
    VDS --> C
    C --> OM_Result
```

- D√©couverte automatique de toutes les sources Dremio configur√©es
- Ingestion des VDS comme vues SQL dans OpenMetadata
- Organisation par sch√©ma (un sch√©ma par source, un sch√©ma d√©di√© pour les VDS)
- Pipeline d'ingestion planifiable (mise √† jour automatique des m√©tadonn√©es)
- Prise en charge de l'authentification Dremio (Basic, LDAP, etc.)


## Pr√©requis

```mermaid
flowchart TD
    A[üöÄ D√©marrage] --> B{Dremio running ?}
    B -->|‚úÖ| C{OpenMetadata up ?}
    B -->|‚ùå| B1[D√©marre Dremio sur :9047]
    C -->|‚úÖ| D{Python 3.8+ ?}
    C -->|‚ùå| C1[Lance OpenMetadata sur :8585]
    D -->|‚úÖ| E{JWT Token r√©cup√©r√© ?}
    D -->|‚ùå| D1[Install Python 3.8+]
    E -->|‚úÖ| F[üéâ Pr√™t √† ing√©rer !]
    E -->|‚ùå| E1[Va chercher ton token dans OM]
    
    B1 --> B
    C1 --> C
    D1 --> D
    E1 --> E
```

- Dremio accessible (`localhost:9047` ou adresse personnalis√©e)
- OpenMetadata op√©rationnel (`localhost:8585` ou adresse personnalis√©e)
- Python 3.8+ avec pip
- Token JWT OpenMetadata (voir section Configuration)


## Installation rapide

```bash

cd dremio/ingestion
pip install -r requirements.txt
cp .env.example .env
# Modifier le fichier .env avec vos param√®tres (voir section Configuration)
python example_usage.py --test-connections
python example_usage.py
```



## Configuration


### R√©cup√©ration du Token JWT OpenMetadata

```mermaid
sequenceDiagram
    participant Toi as üë§ Toi
    participant Browser as üåê Navigateur
    participant OM as üìä OpenMetadata
    
    Toi->>Browser: Ouvre localhost:8585
    Browser->>OM: Connexion
    Toi->>OM: Settings ‚Üí Bots
    OM->>Toi: Liste des bots
    Toi->>OM: Clique sur "ingestion-bot"
    OM->>Toi: D√©tails du bot
    Toi->>OM: "Generate New Token"
    OM->>Toi: üéâ Ton token JWT !
    Toi->>Toi: Copie dans le .env
```

1. Acc√©der √† OpenMetadata : `http://localhost:8585`
2. Aller dans Settings ‚Üí Bots
3. S√©lectionner ou cr√©er le bot d'ingestion
4. G√©n√©rer un nouveau token et le copier dans le fichier `.env`


### Exemple de fichier .env

```bash
# Dremio
DREMIO_HOST=localhost
DREMIO_PORT=9047
DREMIO_USERNAME=admin
DREMIO_PASSWORD=admin123

# OpenMetadata
OPENMETADATA_HOST=localhost
OPENMETADATA_PORT=8585
OPENMETADATA_JWT_TOKEN=eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiIs...

# Options avanc√©es
SERVICE_NAME=Dremio Data Lake Platform
VDS_SCHEMA_NAME=VDS_Analytics
PIPELINE_SCHEDULE=0 6 * * *
```


### Configuration avanc√©e

Le fichier `config/dremio_ingestion.yaml` te permet de :

```yaml
# Filtres
filters:
  include_sources: ["MinIO", "PostgreSQL"]
  exclude_sources: ["Test_DB"]
  include_vds_pattern: "prod_*"

# Performance
performance:
  batch_size: 100
  max_concurrent_requests: 5
  timeout_seconds: 30

# Mapping des types
type_mapping:
  "VARCHAR": "STRING"
  "BIGINT": "LONG"
  "DOUBLE": "FLOAT"
```


## Utilisation


### Mode test (connexion et configuration)

```bash
python example_usage.py --test-connections
```

```mermaid
flowchart LR
    A[üöÄ D√©marrage] --> B[üîç Test Dremio]
    B --> C[üîç Test OpenMetadata]
    C --> D[üìä Aper√ßu donn√©es]
    D --> E[‚úÖ Rapport de sant√©]
```


### Mode dry-run (analyse sans modification)

```bash
python example_usage.py --dry-run
```



### Mode ingestion interactif

```bash
python example_usage.py
```



### Mode automatique (pour int√©gration CI/CD ou batch)

```bash
python dremio_to_openmetadata_ingestion.py --mode ingestion
```


### Options disponibles

```bash
# Tests seulement
python example_usage.py --test-connections

# Analyse sans modification  
python example_usage.py --dry-run

# Mode verbeux (pour debug)
python example_usage.py --verbose

# Force l'update (√©crase les m√©tadonn√©es existantes)
python example_usage.py --force-update

# Ingestion d'une source sp√©cifique
python example_usage.py --source-only MinIO
```


## R√©sultats attendus dans OpenMetadata


### Service "Dremio Data Lake Platform"

```mermaid
graph TB
    Service[üè¢ Dremio Data Lake Platform]
    
    Service --> Schema1[üì¶ MinIO]
    Service --> Schema2[üì¶ PostgreSQL] 
    Service --> Schema3[üì¶ MySQL]
    Service --> SchemaVDS[üì¶ VDS_Analytics]
    
    Schema1 --> T1[üìã customers]
    Schema1 --> T2[üìã orders]
    
    Schema2 --> T3[üìã users]
    Schema2 --> T4[üìã products]
    
    SchemaVDS --> V1[üëÅÔ∏è customer_analytics]
    SchemaVDS --> V2[üëÅÔ∏è monthly_sales]
    SchemaVDS --> V3[üëÅÔ∏è inventory_report]
    
    style Service fill:#e1f5fe
    style Schema1 fill:#f3e5f5
    style Schema2 fill:#f3e5f5
    style Schema3 fill:#f3e5f5
    style SchemaVDS fill:#fff3e0
```


### Pipeline d'ingestion automatique

Apr√®s la premi√®re ingestion, OpenMetadata cr√©e automatiquement :
- Un pipeline planifi√© (quotidien par d√©faut)
- La d√©tection des changements (nouvelles tables, colonnes, VDS)
- Un historique d'ex√©cution consultable dans l'interface


## D√©pannage et diagnostic


### Probl√®mes fr√©quents et solutions

```mermaid
flowchart TD
    Problem[ü§î Un probl√®me ?] --> Check1{Dremio accessible ?}
    
    Check1 -->|‚ùå| Fix1[üîß V√©rifie que Dremio tourne sur :9047]
    Check1 -->|‚úÖ| Check2{Token OM valide ?}
    
    Check2 -->|‚ùå| Fix2[üîë R√©g√©n√®re un token dans OM]
    Check2 -->|‚úÖ| Check3{Erreur de d√©pendances ?}
    
    Check3 -->|‚úÖ| Fix3[üì¶ pip install -r requirements.txt --upgrade]
    Check3 -->|‚ùå| Check4{Timeout API ?}
    
    Check4 -->|‚úÖ| Fix4[‚è±Ô∏è Augmente timeout dans config.yaml]
    Check4 -->|‚ùå| Debug[üêõ Active le mode debug]
    
    Fix1 --> Test[‚úÖ Relance le test]
    Fix2 --> Test
    Fix3 --> Test  
    Fix4 --> Test
    Debug --> Test
```

#### üî• Erreur de connexion Dremio
```bash
# V√©rifier que Dremio r√©pond
curl http://localhost:9047/apiv2/info

# Si √ßa marche pas, check ton .env :
DREMIO_HOST=localhost  # ou ton IP
DREMIO_PORT=9047       # ou ton port custom
```

#### üé´ Token OpenMetadata qui d√©conne
```
Error: 401 Unauthorized - Token verification failed
```
**Solution** : R√©g√©n√©rer un token dans l'interface OpenMetadata.

#### üì¶ D√©pendances cass√©es
```bash
# Force la r√©install de tout
pip install -r requirements.txt --upgrade --force-reinstall
```


#### üêå Timeout sur l'API
Si Dremio est lent √† r√©pondre, ajuster dans `config/dremio_ingestion.yaml` :
```yaml
api:
  timeout: 60
  retries: 3
```


#### üîç Mode debug
Pour activer le mode debug :
```yaml
logging:
  level: "DEBUG"
  file: "debug_dremio.log"
```
Puis lancer :
```bash
python example_usage.py --verbose
```

### üìã Checklist de diagnostic

```bash
# 1. Test des services
curl http://localhost:9047/apiv2/info  # Dremio
curl http://localhost:8585/api/v1/system/version  # OpenMetadata

# 2. Test du connecteur
python example_usage.py --test-connections

# 3. V√©rif des logs
tail -f dremio_ingestion.log

# 4. Test des permissions
python -c "from src.client.dremio_client import DremioClient; print('Import OK')"
```


## Structure du projet

```
dremio/
‚îú‚îÄ‚îÄ üìã README.md                    # Ce que tu lis l√†
‚îú‚îÄ‚îÄ üê≥ docker-compose-auto.yml     # Env Dremio + OpenMetadata
‚îú‚îÄ‚îÄ üìä ingestion/                  # Le c≈ìur du connecteur
‚îÇ   ‚îú‚îÄ‚îÄ üéØ example_usage.py        # Ton point d'entr√©e principal
‚îÇ   ‚îú‚îÄ‚îÄ ‚öôÔ∏è dremio_to_openmetadata_ingestion.py  # Le moteur
‚îÇ   ‚îú‚îÄ‚îÄ üì¶ requirements.txt        # D√©pendances Python
‚îÇ   ‚îú‚îÄ‚îÄ üîß config/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ dremio_ingestion.yaml  # Config avanc√©e
‚îÇ   ‚îî‚îÄ‚îÄ üõ†Ô∏è src/
‚îÇ       ‚îú‚îÄ‚îÄ client/
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ dremio_client.py   # API Dremio
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ openmetadata_client.py  # API OpenMetadata
‚îÇ       ‚îî‚îÄ‚îÄ utils/
‚îÇ           ‚îî‚îÄ‚îÄ config_manager.py   # Gestion config
‚îú‚îÄ‚îÄ üöÄ initEnv/                    # Scripts d'init Dremio
‚îî‚îÄ‚îÄ üìà env/                        # Environnement Docker
```


## Configuration du pipeline automatique


### Planification dans OpenMetadata

Une fois l'ingestion termin√©e, tu peux ajuster le planning dans OpenMetadata :

```mermaid
sequenceDiagram
    participant Toi as üë§ Toi
    participant OM as üìä OpenMetadata
    participant Pipeline as ‚öôÔ∏è Pipeline
    
    Toi->>OM: Services ‚Üí Dremio Data Lake Platform
    OM->>Toi: D√©tails du service
    Toi->>OM: Onglet "Ingestion"
    OM->>Toi: Liste des pipelines
    Toi->>Pipeline: √âdite le pipeline
    Pipeline->>Toi: Options de planification
    Toi->>Pipeline: Choix : Quotidien / Hebdo / Custom
    Pipeline->>OM: Mise √† jour planning
    OM->>Toi: ‚úÖ Pipeline replanifi√© !
```


### Options de planification

- **Quotidien** : `0 6 * * *` (6h du matin)
- **Hebdomadaire** : `0 6 * * 1` (lundi 6h)
- **Bi-quotidien** : `0 6,18 * * *` (6h et 18h)
- **Custom cron** : Ta propre expression


## Bonnes pratiques


### Performance

```yaml
# Dans config/dremio_ingestion.yaml
performance:
  batch_size: 50          # Tables par batch
  concurrent_requests: 3   # Requ√™tes parall√®les
  cache_metadata: true     # Cache les m√©tadonn√©es
  
filters:
  exclude_empty_tables: true     # Ignore les tables vides
  min_table_size: 1000          # Taille min en lignes
```


### S√©curit√©

```bash
# Variables d'environnement (plus s√ªr que le .env)
export DREMIO_PASSWORD="ton_mot_de_passe_super_secret"
export OPENMETADATA_JWT_TOKEN="ton_token_ultra_secret"

# Lance sans fichier .env
python example_usage.py
```


### Monitoring

```yaml
# Active les m√©triques
monitoring:
  enabled: true
  metrics_file: "ingestion_metrics.json"
  
# Logs d√©taill√©s
logging:
  level: "INFO"
  file: "dremio_ingestion.log"
  rotation: "daily"
```


## Contribution et support


### Proposer une am√©lioration

1. **Fork** le projet
2. **Branch** ta feature : `git checkout -b ma-super-feature`
3. **Commit** tes modifs : `git commit -m "Add: super feature"`
4. **Test** que √ßa marche : `python example_usage.py --test-connections`
5. **Push** : `git push origin ma-super-feature`
6. **Pull Request** avec une description claire


### Support

- **Issues GitHub** : Pour les bugs et features
- **Wiki** : Documentation d√©taill√©e
- **Discussions** : Questions g√©n√©rales


### Rapport de bug

Inclus toujours :
```bash
# Version Python
python --version

# Logs d'erreur
tail -20 dremio_ingestion.log

# Config (sans les mots de passe !)
cat .env | grep -v PASSWORD | grep -v TOKEN
```

---


## Conclusion

Ce connecteur permet d'automatiser l'int√©gration des m√©tadonn√©es Dremio dans OpenMetadata, avec une configuration rapide et un pipeline d'ingestion maintenable. Pour toute question ou contribution, se r√©f√©rer √† la section support ou ouvrir une issue sur le repository.